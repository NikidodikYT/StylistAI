# app/api/v1/ai.py

from fastapi import APIRouter, Depends, File, UploadFile, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete
from typing import Optional, List
import os
import uuid
import logging

from app.core.security import get_current_user
from app.db.session import get_db
from app.models.user import User
from app.models.clothing import ClothingItem
from app.models.ai_analysis import AIAnalysis
from app.services.gemini_service import gemini_service
from app.services.marketplace_service import marketplace_service
from app.schemas.ai import (
    AnalyzeImageResponse,
    ClothingAnalysis,
    FindSimilarRequest,
    FindSimilarResponse,
    SimilarProduct,
    ClothingItemInfo,
    AnalysisListResponse,
    AnalysisListItem,
)

router = APIRouter()
logger = logging.getLogger(__name__)

UPLOAD_DIR = "uploads/clothing"
os.makedirs(UPLOAD_DIR, exist_ok=True)


# ============================================================
# HELPER FUNCTIONS
# ============================================================

async def save_uploaded_file(file: UploadFile) -> str:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª."""
    file_extension = os.path.splitext(file.filename)[1]
    unique_filename = f"{uuid.uuid4()}{file_extension}"
    file_path = os.path.join(UPLOAD_DIR, unique_filename)
    
    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    return file_path


async def create_ai_analysis(
    db: AsyncSession,
    user_id: int,
    file_path: str,
    analysis_data: dict,
    item_id: Optional[int] = None,
) -> AIAnalysis:
    """–°–æ–∑–¥–∞—ë—Ç –∑–∞–ø–∏—Å—å –∞–Ω–∞–ª–∏–∑–∞ –≤ –ë–î."""
    ai_analysis = AIAnalysis(
        user_id=user_id,
        prompt=f"Analyze clothing image: {file_path}",
        response=str(analysis_data),
        analysis_data=analysis_data,
        model_used="gemini-2.0-flash",
        clothing_item_id=item_id,
    )
    
    db.add(ai_analysis)
    await db.flush()
    return ai_analysis


async def save_to_wardrobe(
    db: AsyncSession,
    user_id: int,
    file_path: str,
    analysis_data: dict,
) -> Optional[int]:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–µ—â—å –≤ –≥–∞—Ä–¥–µ—Ä–æ–±."""
    try:
        clothing_item = ClothingItem(
            user_id=user_id,
            category=analysis_data.get("category", "unknown"),
            color=", ".join(analysis_data.get("colors", [])),
            brand=analysis_data.get("brand"),
            description=analysis_data.get("description", ""),
            image_url=file_path,
        )
        
        db.add(clothing_item)
        await db.flush()
        logger.info(f"Saved to wardrobe: user={user_id}, item={clothing_item.id}")
        return clothing_item.id
    except Exception as e:
        logger.error(f"Failed to save to wardrobe: {e}")
        return None


async def auto_analyze_item(
    db: AsyncSession,
    item: ClothingItem,
    user_id: int
) -> dict:
    """–ê–≤—Ç–æ–∞–Ω–∞–ª–∏–∑ –≤–µ—â–∏ —á–µ—Ä–µ–∑ Gemini –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—Ç."""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑
    result = await db.execute(
        select(AIAnalysis)
        .where(AIAnalysis.clothing_item_id == item.id)
        .order_by(AIAnalysis.created_at.desc())
    )
    
    existing = result.scalar_one_or_none()
    if existing and existing.analysis_data:
        logger.info(f"Found existing analysis for item {item.id}")
        return existing.analysis_data
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª
    if not item.image_url or not os.path.exists(item.image_url):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Item image not found",
        )
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
    logger.info(f"Auto-analyzing item {item.id}")
    if not gemini_service or not gemini_service.model:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Gemini AI service not available",
        )
    
    analysis_data = await gemini_service.analyze_clothing_image(item.image_url)
    if not analysis_data:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to analyze image",
        )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    ai_analysis = AIAnalysis(
        user_id=user_id,
        clothing_item_id=item.id,
        prompt=f"Auto-analyze: {item.image_url}",
        response=str(analysis_data),
        analysis_data=analysis_data,
        model_used="gemini-2.0-flash",
    )
    
    db.add(ai_analysis)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—â—å
    item.category = analysis_data.get("category") or item.category
    item.color = ", ".join(analysis_data.get("colors", [])) or item.color
    item.brand = analysis_data.get("brand") or item.brand
    item.description = analysis_data.get("description") or item.description
    
    await db.commit()
    await db.refresh(item)
    
    return analysis_data


def build_search_query(item: ClothingItem, analysis_data: dict = None) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç —É–º–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –º–∏–Ω—É—Å-—Å–ª–æ–≤–∞–º–∏.
    –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è varsity / letterman / college jackets.
    """
    if not analysis_data:
        parts = [p for p in [item.category, item.color] if p]
        return " ".join(parts) if parts else "clothing"
    
    category = (analysis_data.get("category") or item.category or "").lower()
    subcategory = (analysis_data.get("subcategory") or "").lower()
    desc = ((analysis_data.get("description") or "") + " " + (item.description or "")).lower()
    analysis_text = " ".join([category, subcategory, desc])
    
    query_parts: List[str] = []
    
    # ----- VARSITY SPECIAL MODE -----
    varsity_triggers = ["varsity", "letterman", "college jacket", "university jacket"]
    is_varsity = any(t in analysis_text for t in varsity_triggers)
    
    if is_varsity:
        colors = analysis_data.get("colors") or []
        if colors:
            query_parts.append(colors[0].lower())
        
        query_parts.append("varsity jacket")
        
        material = (analysis_data.get("material") or "").lower()
        details = (analysis_data.get("details") or "").lower()
        combo = material + " " + details
        
        detail_words: List[str] = []
        for w in ["wool", "leather", "patch", "embroidered", "college", "university"]:
            if w in combo and w not in detail_words:
                detail_words.append(w)
        
        if detail_words:
            query_parts.extend(detail_words[:2])
        
        target = (analysis_data.get("target_audience") or "").lower()
        if target in ["men", "women"]:
            query_parts.append(target)
        
        # –ú–ò–ù–£–°-–°–õ–û–í–ê –¥–ª—è varsity: —É–±–∏—Ä–∞–µ–º —Ö—É–¥–∏, —Å–≤–∏—Ç—à–æ—Ç—ã
        query = " ".join(query_parts).strip()
        query += " -hoodie -sweatshirt -sweater -pullover"
        
        logger.info(f"[VARSITY MODE] Built search query: '{query}'")
        return query
    
    # ----- DEFAULT MODE -----
    query_parts = []
    
    if category and category not in ["unknown", "none"]:
        query_parts.append(category)
    
    colors = analysis_data.get("colors") or []
    if colors:
        query_parts.insert(0, colors[0].lower())
    elif item.color:
        query_parts.insert(0, item.color.split(",")[0].strip().lower())
    
    style = analysis_data.get("style")
    if style and style.lower() not in ["unknown", "none"]:
        query_parts.append(style.lower())
    
    target = (analysis_data.get("target_audience") or "").lower()
    if target in ["men", "women"]:
        query_parts.append(target)
    
    query = " ".join(query_parts).strip()
    
    # –ú–ò–ù–£–°-–°–õ–û–í–ê –¥–ª—è –ª—é–±—ã—Ö jacket: —É–±–∏—Ä–∞–µ–º —Ö—É–¥–∏/—Å–≤–∏—Ç—à–æ—Ç—ã
    if "jacket" in category:
        query += " -hoodie -sweatshirt -sweater -pullover -cardigan"
    
    logger.info(f"[DEFAULT MODE] Built search query: '{query}'")
    return query if query else "clothing"


def is_category_mismatch(product_name: str, source_category: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –ø–æ–ø–∞–ª –ª–∏ —Ç–æ–≤–∞—Ä –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
    –ù–∞–ø—Ä–∏–º–µ—Ä, hoodie –∫–æ–≥–¥–∞ –∏—â–µ–º jacket.
    """
    product_lower = product_name.lower()
    category_lower = source_category.lower()
    
    # –ï—Å–ª–∏ –∏—â–µ–º jacket, –∞ –Ω–∞—à–ª–∏ —Ö—É–¥–∏/—Å–≤–∏—Ç—à–æ—Ç - —ç—Ç–æ –º—É—Å–æ—Ä
    if "jacket" in category_lower:
        wrong_items = [
            "hoodie", "sweatshirt", "sweater", "pullover", 
            "cardigan", "tshirt", "t-shirt", "shirt",
            "pants", "jeans", "shorts", "skirt"
        ]
        if any(word in product_lower for word in wrong_items):
            return True
    
    # –ï—Å–ª–∏ –∏—â–µ–º pants/jeans, –∞ –Ω–∞—à–ª–∏ jacket/shirt - –º—É—Å–æ—Ä
    if any(x in category_lower for x in ["pants", "jeans", "trousers"]):
        if any(x in product_lower for x in ["jacket", "coat", "shirt", "hoodie"]):
            return True
    
    # –ï—Å–ª–∏ –∏—â–µ–º shirt, –∞ –Ω–∞—à–ª–∏ jacket/pants - –º—É—Å–æ—Ä
    if "shirt" in category_lower and "shirt" not in product_lower:
        if any(x in product_lower for x in ["jacket", "coat", "pants", "jeans"]):
            return True
    
    return False


def calculate_similarity_score(
    product: dict,
    analysis_data: dict,
    item: ClothingItem
) -> float:
    """
    –°—á–∏—Ç–∞–µ—Ç similarity score 0-100 —Å –∂—ë—Å—Ç–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π.
    """
    score = 0.0
    
    name = product.get("name", "")
    brand = product.get("brand", "")
    product_text = f"{name} {brand}".lower()
    
    category = (analysis_data.get("category") or item.category or "").lower()
    subcategory = (analysis_data.get("subcategory") or "").lower()
    desc = ((analysis_data.get("description") or "") + " " + (item.description or "")).lower()
    analysis_text = " ".join([category, subcategory, desc])
    
    # ===== –ö–ê–¢–ï–ì–û–†–ò–ô–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê (–ñ–Å–°–¢–ö–ê–Ø) =====
    if is_category_mismatch(name, category):
        logger.debug(f"Category mismatch: '{name}' vs category '{category}'")
        return 0.0  # –°—Ä–∞–∑—É —Ä–µ–∂–µ–º –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    
    # ----- 1. Varsity-–º–∞—Ç—Ä–∏—Ü–∞ (–¥–æ 40 –±–∞–ª–ª–æ–≤) -----
    varsity_triggers = {
        "varsity": 18,
        "letterman": 12,
        "college": 8,
        "university": 6,
        "patch": 5,
        "chenille": 5,
        "wool": 5,
        "leather": 5,
    }
    
    is_source_varsity = any(
        k in analysis_text
        for k in ["varsity", "letterman", "college jacket", "university jacket"]
    )
    
    if is_source_varsity:
        varsity_score = 0.0
        for word, weight in varsity_triggers.items():
            if word in product_text:
                varsity_score += weight
        varsity_score = min(varsity_score, 40.0)
        score += varsity_score
        
        # –®—Ç—Ä–∞—Ñ –µ—Å–ª–∏ –∏—â–µ–º varsity, –Ω–æ –≤ —Ç–æ–≤–∞—Ä–µ —ç—Ç–æ–≥–æ –Ω–µ—Ç
        if not any(t in product_text for t in ["varsity", "letterman", "college"]):
            score -= 20
    
    # ----- 2. –ö–∞—Ç–µ–≥–æ—Ä–∏—è (–¥–æ 25 –±–∞–ª–ª–æ–≤) -----
    if category:
        cat_words = [w for w in category.split() if len(w) > 3]
        if cat_words:
            matches = sum(1 for w in cat_words if w in product_text)
            if matches > 0:
                score += (matches / len(cat_words)) * 25
    
    # ----- 3. –¶–≤–µ—Ç–∞ (–¥–æ 15 –±–∞–ª–ª–æ–≤) -----
    colors = analysis_data.get("colors") or []
    if colors:
        col_matches = sum(1 for c in colors if c.lower() in product_text)
        if col_matches > 0:
            score += (col_matches / len(colors)) * 15
    
    # ----- 4. –°—Ç–∏–ª—å (–¥–æ 10 –±–∞–ª–ª–æ–≤) -----
    style = (analysis_data.get("style") or "").lower()
    if style and style in product_text:
        score += 10
    
    # ----- 5. Subcategory (–¥–æ 10 –±–∞–ª–ª–æ–≤) -----
    sub = subcategory
    if sub:
        sub_words = [w for w in sub.split() if len(w) > 3]
        if sub_words:
            sub_matches = sum(1 for w in sub_words if w in product_text)
            if sub_matches > 0:
                score += (sub_matches / len(sub_words)) * 10
    
    # ----- 6. –ú–∞—Ç–µ—Ä–∏–∞–ª (–¥–æ 5 –±–∞–ª–ª–æ–≤) -----
    material = (analysis_data.get("material") or "").lower()
    if material and len(material) > 3:
        mat_words = [w for w in material.split() if len(w) > 3]
        if any(w in product_text for w in mat_words):
            score += 5
    
    # ----- 7. –ë—Ä–µ–Ω–¥ (–¥–æ 5 –±–∞–ª–ª–æ–≤) -----
    brand_src = (analysis_data.get("brand") or item.brand or "").lower()
    if brand_src and brand_src not in ["unknown", "unbranded", "none"]:
        if brand_src in product_text:
            score += 5
    
    return min(max(score, 0.0), 100.0)


# ============================================================
# ENDPOINTS
# ============================================================

@router.post("/analyze-image", response_model=AnalyzeImageResponse)
async def analyze_image(
    file: UploadFile = File(...),
    save_to_wardrobe_flag: bool = False,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
):
    """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–¥–µ–∂–¥—ã —á–µ—Ä–µ–∑ Gemini AI."""
    
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="File must be an image",
        )
    
    file_path: Optional[str] = None
    try:
        file_path = await save_uploaded_file(file)
        
        if not gemini_service or not gemini_service.model:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Gemini AI service not available",
            )
        
        analysis_data = await gemini_service.analyze_clothing_image(file_path)
        if not analysis_data:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to analyze image",
            )
        
        item_id: Optional[int] = None
        if save_to_wardrobe_flag:
            item_id = await save_to_wardrobe(
                db, current_user.id, file_path, analysis_data
            )
        
        ai_analysis = await create_ai_analysis(
            db, current_user.id, file_path, analysis_data, item_id
        )
        
        await db.commit()
        
        return AnalyzeImageResponse(
            success=True,
            analysis_id=ai_analysis.id,
            item_id=item_id,
            saved_to_wardrobe=save_to_wardrobe_flag and item_id is not None,
            clothing=ClothingAnalysis(**analysis_data),
            image_path=file_path,
            created_at=ai_analysis.created_at,
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Analysis error: {e}")
        await db.rollback()
        if file_path and os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Analysis failed: {str(e)}",
        )


@router.post("/find-similar", response_model=FindSimilarResponse)
async def find_similar_products(
    request: FindSimilarRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
):
    """
    –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –∞–≤—Ç–æ–∞–Ω–∞–ª–∏–∑–æ–º, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ fallback.
    """
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –≤–µ—â—å
    result = await db.execute(
        select(ClothingItem).where(
            ClothingItem.id == request.item_id,
            ClothingItem.user_id == current_user.id,
        )
    )
    
    item = result.scalar_one_or_none()
    if not item:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Item not found",
        )
    
    # 2. –í–°–ï–ì–î–ê –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑ —Å —Ç–µ–≥–∞–º–∏
    result = await db.execute(
        select(AIAnalysis)
        .where(AIAnalysis.clothing_item_id == item.id)
        .order_by(AIAnalysis.created_at.desc())
    )
    
    existing_analysis = result.scalar_one_or_none()
    analysis_data = None
    
    if existing_analysis and existing_analysis.analysis_data:
        analysis_data = existing_analysis.analysis_data
        logger.info(f"Loaded existing analysis for item {item.id}")
        
        if "tags" not in analysis_data or not analysis_data.get("tags"):
            logger.warning(f"Old analysis without tags, re-analyzing item {item.id}")
            analysis_data = await auto_analyze_item(db, item, current_user.id)
    else:
        logger.info(f"No analysis for item {item.id}, analyzing now")
        analysis_data = await auto_analyze_item(db, item, current_user.id)
    
    if not analysis_data:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to analyze item"
        )
    
    # 3. –°—Ç—Ä–æ–∏–º –∑–∞–ø—Ä–æ—Å
    search_query = build_search_query(item, analysis_data)
    logger.info(f"üîç Search query: '{search_query}'")
    logger.info(f"üìù Analysis tags: {analysis_data.get('tags', [])}")
    
    # 4. –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã
    try:
        raw_products = await marketplace_service.search_similar(
            search_query=search_query,
            marketplaces=request.marketplaces,
            max_results_per_marketplace=request.max_results_per_marketplace,
        )
        
        logger.info(f"‚úÖ Found {len(raw_products)} raw products")
        
        fallback_used = False
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø—Ä–æ–±—É–µ–º fallback —Å —É–ø—Ä–æ—â—ë–Ω–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
        if not raw_products:
            logger.warning("‚ùå No products found, trying fallback with simplified query")
            
            # –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: —Ç–æ–ª—å–∫–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è + —Ü–≤–µ—Ç
            fallback_query = analysis_data.get("category", "clothing")
            colors = analysis_data.get("colors") or []
            if colors:
                fallback_query = f"{colors[0]} {fallback_query}"
            
            logger.info(f"üîÑ Fallback query: '{fallback_query}'")
            
            raw_products = await marketplace_service.search_similar(
                search_query=fallback_query,
                marketplaces=request.marketplaces,
                max_results_per_marketplace=request.max_results_per_marketplace + 5,
            )
            
            fallback_used = len(raw_products) > 0
            logger.info(f"üîÑ Fallback returned {len(raw_products)} products")
        
        # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –ø—É—Å—Ç–æ ‚Äî –æ—Ç–¥–∞—ë–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if not raw_products:
            return FindSimilarResponse(
                success=True,
                item=ClothingItemInfo(
                    id=item.id,
                    category=item.category,
                    color=item.color,
                    brand=item.brand,
                    description=item.description,
                    image_url=item.image_url,
                ),
                similar_products=[],
                total_found=0,
                search_query=search_query,
                min_score_filter=request.min_similarity_score,
                fallback_used=False,
            )
        
        # 5. –ü–û–°–¢-–§–ò–õ–¨–¢–†–ê–¶–ò–Ø: —É–±–∏—Ä–∞–µ–º google.com/search —Å—Å—ã–ª–∫–∏
        clean_products = [
            p for p in raw_products
            if p.get("url") and "google.com/search" not in p["url"]
        ]
        
        if len(clean_products) < len(raw_products):
            logger.info(
                f"üßπ Removed {len(raw_products) - len(clean_products)} "
                f"products with google.com/search URLs"
            )
        
        # 6. –§–∏–ª—å—Ç—Ä—É–µ–º –∏ —Ä–∞–Ω–∂–∏—Ä—É–µ–º
        scored_products = []
        for product in clean_products:
            score = calculate_similarity_score(product, analysis_data, item)
            product["similarity_score"] = round(score, 1)
            scored_products.append(product)
        
        scored_products.sort(key=lambda x: x.get("similarity_score", 0), reverse=True)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        for i, p in enumerate(scored_products[:5]):
            logger.info(
                f"üèÜ Top {i+1}: {p.get('name')[:60]} - "
                f"Score: {p.get('similarity_score')}"
            )
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥ similarity
        filtered = [
            SimilarProduct(**p) for p in scored_products
            if p.get("similarity_score", 0) >= request.min_similarity_score
        ]
        
        logger.info(
            f"‚úÇÔ∏è After filter (>={request.min_similarity_score}): "
            f"{len(filtered)}/{len(scored_products)} products"
        )
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ –ø—É—Å—Ç–æ, –Ω–æ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ‚Äî –æ—Ç–¥–∞—ë–º —Ç–æ–ø-5 —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        if not filtered and scored_products:
            logger.warning(
                "‚ö†Ô∏è No products passed filter, returning top 5 with lower threshold"
            )
            filtered = [SimilarProduct(**p) for p in scored_products[:5]]
        
        return FindSimilarResponse(
            success=True,
            item=ClothingItemInfo(
                id=item.id,
                category=item.category,
                color=item.color,
                brand=item.brand,
                description=item.description,
                image_url=item.image_url,
            ),
            similar_products=filtered,
            total_found=len(filtered),
            search_query=search_query,
            min_score_filter=request.min_similarity_score,
            fallback_used=fallback_used,
        )
    
    except Exception as e:
        logger.error(f"‚ùå Search error: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Search failed: {str(e)}",
        )


@router.post("/re-analyze/{item_id}")
async def re_analyze_item(
    item_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
):
    """–ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –ø–µ—Ä–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—â—å (–¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–≥–æ–≤)."""
    
    result = await db.execute(
        select(ClothingItem).where(
            ClothingItem.id == item_id,
            ClothingItem.user_id == current_user.id,
        )
    )
    
    item = result.scalar_one_or_none()
    if not item:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Item not found"
        )
    
    if not item.image_url or not os.path.exists(item.image_url):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Image not found"
        )
    
    logger.info(f"üîÑ Force re-analyzing item {item_id}")
    
    if not gemini_service or not gemini_service.model:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Gemini AI not available"
        )
    
    analysis_data = await gemini_service.analyze_clothing_image(item.image_url)
    if not analysis_data:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Analysis failed"
        )
    
    ai_analysis = AIAnalysis(
        user_id=current_user.id,
        clothing_item_id=item.id,
        prompt=f"Force re-analyze: {item.image_url}",
        response=str(analysis_data),
        analysis_data=analysis_data,
        model_used="gemini-2.0-flash",
    )
    
    db.add(ai_analysis)
    
    item.category = analysis_data.get("category") or item.category
    item.color = ", ".join(analysis_data.get("colors", [])) or item.color
    item.brand = analysis_data.get("brand") or item.brand
    item.description = analysis_data.get("description") or item.description
    
    await db.commit()
    
    tags = analysis_data.get("tags", [])
    search_query = " ".join(tags[:5]) if tags else "unknown"
    
    logger.info(f"‚úÖ Re-analysis complete. Tags: {tags}")
    
    return {
        "success": True,
        "message": "Re-analyzed successfully",
        "item_id": item_id,
        "category": analysis_data.get("category"),
        "tags": tags,
        "search_query": search_query,
        "colors": analysis_data.get("colors", []),
        "style": analysis_data.get("style"),
    }


@router.delete("/clear-analysis/{item_id}")
async def clear_old_analysis(
    item_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
):
    """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —Å—Ç–∞—Ä—ã–µ –∞–Ω–∞–ª–∏–∑—ã –¥–ª—è –≤–µ—â–∏ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)."""
    
    result = await db.execute(
        select(ClothingItem).where(
            ClothingItem.id == item_id,
            ClothingItem.user_id == current_user.id,
        )
    )
    
    item = result.scalar_one_or_none()
    if not item:
        raise HTTPException(status_code=404, detail="Item not found")
    
    await db.execute(
        delete(AIAnalysis).where(AIAnalysis.clothing_item_id == item_id)
    )
    
    await db.commit()
    
    logger.info(f"üóëÔ∏è Cleared all analyses for item {item_id}")
    
    return {"success": True, "message": f"Cleared analyses for item {item_id}"}


@router.get("/analyses", response_model=AnalysisListResponse)
async def get_user_analyses(
    limit: int = 50,
    offset: int = 0,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
):
    """–°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    
    result = await db.execute(
        select(AIAnalysis)
        .where(AIAnalysis.user_id == current_user.id)
        .order_by(AIAnalysis.created_at.desc())
        .limit(limit)
        .offset(offset)
    )
    
    analyses = result.scalars().all()
    
    analyses_list = [
        AnalysisListItem(
            id=a.id,
            clothing=ClothingAnalysis(**a.analysis_data) if a.analysis_data else None,
            saved_to_wardrobe=a.clothing_item_id is not None,
            created_at=a.created_at,
        )
        for a in analyses
        if a.analysis_data
    ]
    
    return AnalysisListResponse(total=len(analyses_list), analyses=analyses_list)
